{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "9791dc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YMJ QNRJ NX MJW QJFXY QNPJI KWZNY , GZY YMJ GFSFSF NX RD QJFXY QNPJI .\n",
      "\n",
      "MJ XFB F TQI DJQQTB YWZHP .\n",
      "\n",
      "THE LIME IS HER LEAST LIKED FRUIT , BUT THE BANANA IS MY LEAST LIKED .\n",
      "\n",
      "HE SAW A OLD YELLOW TRUCK .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./cipher.txt','r') as labels:\n",
    "    for l in labels.readlines()[:2]:\n",
    "        print(l)\n",
    "\n",
    "with open('./plaintext.txt') as features:\n",
    "    for l in features.readlines()[:2]:\n",
    "        print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "cb8db428",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "import os\n",
    "def load_data(path):\n",
    "    file = os.path.join(path)\n",
    "    with open (file,'r') as f:\n",
    "        data=f.read()\n",
    "    return data.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "f1fb7bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = load_data('cipher.txt')\n",
    "features = load_data('plaintext.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "8bd56521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['YMJ QNRJ NX MJW QJFXY QNPJI KWZNY , GZY YMJ GFSFSF NX RD QJFXY QNPJI .',\n",
       " 'MJ XFB F TQI DJQQTB YWZHP .',\n",
       " 'NSINF NX WFNSD IZWNSL OZSJ , FSI NY NX XTRJYNRJX BFWR NS STAJRGJW .',\n",
       " 'YMFY HFY BFX RD RTXY QTAJI FSNRFQ .',\n",
       " 'MJ INXQNPJX LWFUJKWZNY , QNRJX , FSI QJRTSX .']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "f3ff6366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['THE LIME IS HER LEAST LIKED FRUIT , BUT THE BANANA IS MY LEAST LIKED .',\n",
       " 'HE SAW A OLD YELLOW TRUCK .',\n",
       " 'INDIA IS RAINY DURING JUNE , AND IT IS SOMETIMES WARM IN NOVEMBER .',\n",
       " 'THAT CAT WAS MY MOST LOVED ANIMAL .',\n",
       " 'HE DISLIKES GRAPEFRUIT , LIMES , AND LEMONS .']"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "86a1e297",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "def tokenize(text):\n",
    "    x_tk = Tokenizer(char_level=True)\n",
    "    x_tk.fit_on_texts(text)\n",
    "    \n",
    "    return x_tk.texts_to_sequences(text),x_tk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "2baa5fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sentences = [\n",
    "    'The quick brown fox jumps over the lazy dog .',\n",
    "    'By Jove , my quick study of lexicography won a prize .',\n",
    "    'This is a short sentence .']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "0181e1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 1, 'e': 2, 'o': 3, 't': 4, 'i': 5, 's': 6, 'h': 7, 'r': 8, 'y': 9, 'u': 10, 'c': 11, 'n': 12, 'a': 13, 'p': 14, '.': 15, 'q': 16, 'k': 17, 'b': 18, 'w': 19, 'f': 20, 'x': 21, 'j': 22, 'm': 23, 'v': 24, 'l': 25, 'z': 26, 'd': 27, 'g': 28, ',': 29}\n",
      "\n",
      "\n",
      "sentence1\n",
      "\n",
      "\n",
      "original sentence: The quick brown fox jumps over the lazy dog .\n",
      "embedded: [4, 7, 2, 1, 16, 10, 5, 11, 17, 1, 18, 8, 3, 19, 12, 1, 20, 3, 21, 1, 22, 10, 23, 14, 6, 1, 3, 24, 2, 8, 1, 4, 7, 2, 1, 25, 13, 26, 9, 1, 27, 3, 28, 1, 15]\n",
      "sentence2\n",
      "\n",
      "\n",
      "original sentence: By Jove , my quick study of lexicography won a prize .\n",
      "embedded: [18, 9, 1, 22, 3, 24, 2, 1, 29, 1, 23, 9, 1, 16, 10, 5, 11, 17, 1, 6, 4, 10, 27, 9, 1, 3, 20, 1, 25, 2, 21, 5, 11, 3, 28, 8, 13, 14, 7, 9, 1, 19, 3, 12, 1, 13, 1, 14, 8, 5, 26, 2, 1, 15]\n",
      "sentence3\n",
      "\n",
      "\n",
      "original sentence: This is a short sentence .\n",
      "embedded: [4, 7, 5, 6, 1, 5, 6, 1, 13, 1, 6, 7, 3, 8, 4, 1, 6, 2, 12, 4, 2, 12, 11, 2, 1, 15]\n"
     ]
    }
   ],
   "source": [
    "text_tokenized, text_tokenizer = tokenize(text_sentences)\n",
    "print(text_tokenizer.word_index)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "\n",
    "for i,(f,c) in enumerate(zip(text_sentences,text_tokenized)):\n",
    "    print('sentence{}'.format(i+1))\n",
    "    print('\\n')\n",
    "    print('original sentence: {}'.format(f))\n",
    "    print('embedded: {}'.format(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "9125d6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#padding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "\n",
    "def padding(seq,l=None):\n",
    "    padded = pad_sequences(\n",
    "    seq,\n",
    "    maxlen=l,\n",
    "    padding='post')\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "712607f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  7,  2,  1, 16, 10,  5, 11, 17,  1, 18,  8,  3, 19, 12,  1, 20,\n",
       "        3, 21,  1, 22, 10, 23, 14,  6,  1,  3, 24,  2,  8,  1,  4,  7,  2,\n",
       "        1, 25, 13, 26,  9,  1, 27,  3, 28,  1, 15,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0], dtype=int32)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tokenized = padding(text_tokenized)\n",
    "text_tokenized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c7f1ed19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x,y):\n",
    "    x_preprocessed, x_tokenizer = tokenize(x)\n",
    "    y_preprocessed, y_tokenizer = tokenize(y)\n",
    "    \n",
    "    x_preprocessed = padding(x_preprocessed)\n",
    "    y_preprocessed = padding(y_preprocessed)\n",
    "    \n",
    "    x_preprocessed = x_preprocessed.reshape(*x_preprocessed.shape,1)\n",
    "    y_preprocessed = y_preprocessed.reshape(*y_preprocessed.shape,1)\n",
    "    \n",
    "    return x_preprocessed,y_preprocessed,x_tokenizer,y_tokenizer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "3066232c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 1, 'i': 2, 'e': 3, 's': 4, 't': 5, 'r': 6, 'n': 7, 'a': 8, 'u': 9, 'l': 10, 'd': 11, 'o': 12, 'm': 13, 'h': 14, 'y': 15, 'g': 16, 'b': 17, ',': 18, '.': 19, 'f': 20, 'p': 21, 'c': 22, 'v': 23, 'w': 24, 'k': 25, 'j': 26, 'x': 27, 'q': 28, 'z': 29, '?': 30, \"'\": 31}\n",
      "{' ': 1, 'n': 2, 'j': 3, 'x': 4, 'y': 5, 'w': 6, 's': 7, 'f': 8, 'z': 9, 'q': 10, 'i': 11, 't': 12, 'r': 13, 'm': 14, 'd': 15, 'l': 16, 'g': 17, ',': 18, '.': 19, 'k': 20, 'u': 21, 'h': 22, 'a': 23, 'b': 24, 'p': 25, 'o': 26, 'c': 27, 'v': 28, 'e': 29, '?': 30, \"'\": 31}\n"
     ]
    }
   ],
   "source": [
    "features,labels,x_tr,y_tr = preprocess(features,codes)\n",
    "print(x_tr.word_index)\n",
    "print(y_tr.word_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "72ac280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model architecture\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense,GRU,Input, TimeDistributed\n",
    "from keras.layers import Activation\n",
    "from keras.losses import sparse_categorical_crossentropy\n",
    "\n",
    "def simple_mdel(input_shape,output_seq_length,code_vocab_size,features_vocab_size):\n",
    "    inputs = Input(input_shape[1:])\n",
    "    layer1 = GRU(100,return_sequences=True)(inputs)\n",
    "    #utputs = Dense(features_vocab_size)(layer1)\n",
    "    outputs = TimeDistributed(Dense(features_vocab_size))(layer1)\n",
    "    output = Activation('softmax')(outputs)\n",
    "    model = Model(inputs,output)\n",
    "    model.compile(optimizer=\"Adam\", loss=sparse_categorical_crossentropy, metrics=[\"acc\"])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a8d04308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "125/125 [==============================] - 5s 35ms/step - loss: 1.7428 - acc: 0.5337 - val_loss: 1.0870 - val_acc: 0.6736\n",
      "Epoch 2/8\n",
      "125/125 [==============================] - 4s 34ms/step - loss: 0.8625 - acc: 0.7535 - val_loss: 0.6808 - val_acc: 0.8259\n",
      "Epoch 3/8\n",
      "125/125 [==============================] - 4s 34ms/step - loss: 0.5441 - acc: 0.8712 - val_loss: 0.4300 - val_acc: 0.9077\n",
      "Epoch 4/8\n",
      "125/125 [==============================] - 4s 34ms/step - loss: 0.3435 - acc: 0.9273 - val_loss: 0.2737 - val_acc: 0.9442\n",
      "Epoch 5/8\n",
      "125/125 [==============================] - 4s 34ms/step - loss: 0.2255 - acc: 0.9552 - val_loss: 0.1867 - val_acc: 0.9650\n",
      "Epoch 6/8\n",
      "125/125 [==============================] - 4s 34ms/step - loss: 0.1605 - acc: 0.9696 - val_loss: 0.1385 - val_acc: 0.9725\n",
      "Epoch 7/8\n",
      "125/125 [==============================] - 4s 34ms/step - loss: 0.1229 - acc: 0.9747 - val_loss: 0.1094 - val_acc: 0.9775\n",
      "Epoch 8/8\n",
      "125/125 [==============================] - 4s 34ms/step - loss: 0.0993 - acc: 0.9788 - val_loss: 0.0900 - val_acc: 0.9802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f498c1492e0>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = simple_mdel(features.shape,labels.shape[1],len(x_tr.word_index)+1,len(y_tr.word_index)+1)\n",
    "model.fit(features,labels,batch_size=64,epochs=8,validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "802c66f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert logits to char\n",
    "def convertion(pred,tokenizer):\n",
    "    idx_to_char = {i:char for char,i in tokenizer.word_index.items()}\n",
    "    idx_to_char[0] = '    '\n",
    "    conv = ''.join(idx_to_char[prediction] for prediction in np.argmax(pred,axis=1))\n",
    "    conv.replace('<PAD>', \"1\")\n",
    "        \n",
    "    return conv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "3b9e25f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the uime is her least liked fruit , but the banana is my least liked .                                                                                                                            \n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(features[:1])[0]\n",
    "print(convertion(pred,x_tr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "6e8420be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE LIME IS HER LEAST LIKED FRUIT , BUT THE BANANA IS MY LEAST LIKED .\n"
     ]
    }
   ],
   "source": [
    "original_text = load_data('plaintext.txt')[0]\n",
    "print(original_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
